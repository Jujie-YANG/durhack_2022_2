{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark QRT\n",
    "\n",
    "This notebook illustrates a simple benchmark example that should help novice participants to start the competition.\n",
    "\n",
    "## Used libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "The train and test inputs are composed of 46 features.\n",
    "\n",
    "The target of this challenge is `RET` and corresponds to the fact that the **return is in the top 50% of highest stock returns**.\n",
    "\n",
    "Since the median is very close to 0, this information should not change much with the idea to predict the sign of the return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>STOCK</th>\n",
       "      <th>INDUSTRY</th>\n",
       "      <th>INDUSTRY_GROUP</th>\n",
       "      <th>SECTOR</th>\n",
       "      <th>SUB_INDUSTRY</th>\n",
       "      <th>RET_1</th>\n",
       "      <th>VOLUME_1</th>\n",
       "      <th>RET_2</th>\n",
       "      <th>VOLUME_2</th>\n",
       "      <th>...</th>\n",
       "      <th>VOLUME_16</th>\n",
       "      <th>RET_17</th>\n",
       "      <th>VOLUME_17</th>\n",
       "      <th>RET_18</th>\n",
       "      <th>VOLUME_18</th>\n",
       "      <th>RET_19</th>\n",
       "      <th>VOLUME_19</th>\n",
       "      <th>RET_20</th>\n",
       "      <th>VOLUME_20</th>\n",
       "      <th>RET</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>-0.015748</td>\n",
       "      <td>0.147931</td>\n",
       "      <td>-0.015504</td>\n",
       "      <td>0.179183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.630899</td>\n",
       "      <td>0.003254</td>\n",
       "      <td>-0.379412</td>\n",
       "      <td>0.008752</td>\n",
       "      <td>-0.110597</td>\n",
       "      <td>-0.012959</td>\n",
       "      <td>0.174521</td>\n",
       "      <td>-0.002155</td>\n",
       "      <td>-0.000937</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>104</td>\n",
       "      <td>0.003984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.090580</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003774</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.018518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.028777</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.034722</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>142</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>-0.096282</td>\n",
       "      <td>-0.058896</td>\n",
       "      <td>0.084771</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010336</td>\n",
       "      <td>-0.017612</td>\n",
       "      <td>-0.354333</td>\n",
       "      <td>-0.006562</td>\n",
       "      <td>-0.519391</td>\n",
       "      <td>-0.012101</td>\n",
       "      <td>-0.356157</td>\n",
       "      <td>-0.006867</td>\n",
       "      <td>-0.308868</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.031298</td>\n",
       "      <td>-0.429540</td>\n",
       "      <td>0.007756</td>\n",
       "      <td>-0.089919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012105</td>\n",
       "      <td>0.033824</td>\n",
       "      <td>-0.290178</td>\n",
       "      <td>-0.001468</td>\n",
       "      <td>-0.663834</td>\n",
       "      <td>-0.013520</td>\n",
       "      <td>-0.562126</td>\n",
       "      <td>-0.036745</td>\n",
       "      <td>-0.631458</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>36</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>92</td>\n",
       "      <td>0.027273</td>\n",
       "      <td>-0.847155</td>\n",
       "      <td>-0.039302</td>\n",
       "      <td>-0.943033</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.277083</td>\n",
       "      <td>-0.012659</td>\n",
       "      <td>0.139086</td>\n",
       "      <td>0.004237</td>\n",
       "      <td>-0.017547</td>\n",
       "      <td>0.004256</td>\n",
       "      <td>0.579510</td>\n",
       "      <td>-0.040817</td>\n",
       "      <td>0.802806</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    DATE  STOCK  INDUSTRY  INDUSTRY_GROUP  SECTOR  SUB_INDUSTRY     RET_1  \\\n",
       "ID                                                                          \n",
       "0      0      2        18               5       3            44 -0.015748   \n",
       "1      0      3        43              15       6           104  0.003984   \n",
       "2      0      4        57              20       8           142  0.000440   \n",
       "3      0      8         1               1       1             2  0.031298   \n",
       "4      0     14        36              12       5            92  0.027273   \n",
       "\n",
       "    VOLUME_1     RET_2  VOLUME_2  ...  VOLUME_16    RET_17  VOLUME_17  \\\n",
       "ID                                ...                                   \n",
       "0   0.147931 -0.015504  0.179183  ...   0.630899  0.003254  -0.379412   \n",
       "1        NaN -0.090580       NaN  ...        NaN  0.003774        NaN   \n",
       "2  -0.096282 -0.058896  0.084771  ...  -0.010336 -0.017612  -0.354333   \n",
       "3  -0.429540  0.007756 -0.089919  ...   0.012105  0.033824  -0.290178   \n",
       "4  -0.847155 -0.039302 -0.943033  ...  -0.277083 -0.012659   0.139086   \n",
       "\n",
       "      RET_18  VOLUME_18    RET_19  VOLUME_19    RET_20  VOLUME_20    RET  \n",
       "ID                                                                        \n",
       "0   0.008752  -0.110597 -0.012959   0.174521 -0.002155  -0.000937   True  \n",
       "1  -0.018518        NaN -0.028777        NaN -0.034722        NaN   True  \n",
       "2  -0.006562  -0.519391 -0.012101  -0.356157 -0.006867  -0.308868  False  \n",
       "3  -0.001468  -0.663834 -0.013520  -0.562126 -0.036745  -0.631458  False  \n",
       "4   0.004237  -0.017547  0.004256   0.579510 -0.040817   0.802806  False  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = pd.read_csv('../data/x_train.csv', index_col='ID')\n",
    "y_train = pd.read_csv('../data/y_train.csv', index_col='ID')\n",
    "train = pd.concat([x_train, y_train], axis=1)\n",
    "test = pd.read_csv('../data/x_test.csv', index_col='ID')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "The main drawback in this challenge would be to deal with the noise. To do that, we could create some feature that aggregate features with some statistics. \n",
    "\n",
    "The following cell computes statistics on a given target conditionally to some features. For example, we want to generate a feature that describe the mean of `RET_1` conditionally to the `SECTOR` and the `DATE`.\n",
    "\n",
    "**Ideas of improvement**: change shifts, the conditional features, the statistics, and the target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "new_features = []\n",
    "\n",
    "# Conditional aggregated features\n",
    "shifts = [i for i in range(1,21)]  # Choose some different shifts\n",
    "statistics = ['mean']  # the type of stat\n",
    "\n",
    "# GROUP BY 4 features only for \"RET\", shifts = [1,...,21]\n",
    "# gb_features = ['STOCK','SECTOR','INDUSTRY', 'DATE']\n",
    "# target_feature = ['RET']\n",
    "# tmp_name = '_'.join(gb_features)\n",
    "# for j in target_feature:\n",
    "#     for shift in shifts:\n",
    "#         for stat in statistics:\n",
    "#             name = f'{j}_{shift}_{tmp_name}_{stat}'\n",
    "#             feat = f'{j}_{shift}'\n",
    "#             new_features.append(name)\n",
    "#             for data in [train, test]:\n",
    "#                 data[name] = data.groupby(gb_features)[feat].transform(stat)\n",
    "           \n",
    "        \n",
    "# # GROUP BY \"DATE\" for features['RET','VOLUME'], shifts=[1,...,21]\n",
    "# gb_features = ['DATE']\n",
    "# target_features = ['RET','VOLUME']\n",
    "# tmp_name = '_'.join(gb_features)\n",
    "# for j in target_features:\n",
    "# #     target_feature = j\n",
    "#     for shift in shifts:\n",
    "#         for stat in statistics:\n",
    "#             name = f'{j}_{shift}_{tmp_name}_{stat}'\n",
    "#             feat = f'{j}_{shift}'\n",
    "#             new_features.append(name)\n",
    "#             for data in [train, test]:\n",
    "#                 data[name] = data.groupby(gb_features)[feat].transform(stat)\n",
    "\n",
    "        \n",
    "# GROUP BY \"STOCK\" for features['RET','VOLUME'], shifts=[1,...,21]\n",
    "gb_features = ['STOCK']\n",
    "target_features = ['RET','VOLUME']\n",
    "tmp_name = '_'.join(gb_features)\n",
    "for j in target_features:\n",
    "#     target_feature = j\n",
    "    for shift in shifts:\n",
    "        for stat in statistics:\n",
    "            name = f'{j}_{shift}_{tmp_name}_{stat}'\n",
    "            feat = f'{j}_{shift}'\n",
    "            new_features.append(name)\n",
    "            for data in [train, test]:\n",
    "                data[name] = data.groupby(gb_features)[feat].transform(stat)\n",
    "\n",
    "                \n",
    "gb_features = ['STOCK','SECTOR','INDUSTRY', 'DATE']\n",
    "target_feature = \"VOLUME\"\n",
    "shifts = [1,13]\n",
    "tmp_name = '_'.join(gb_features)\n",
    "for shift in shifts:\n",
    "    for stat in statistics:\n",
    "        name = f'{target_feature}_{shift}_{tmp_name}_{stat}'\n",
    "        feat = f'{target_feature}_{shift}'\n",
    "        new_features.append(name)\n",
    "        for data in [train, test]:\n",
    "            data[name] = data.groupby(gb_features)[feat].transform(stat)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection\n",
    "\n",
    "To reduce the number of feature (and the noise) we only consider the 5 last days of `RET` and `VOLUME` in addition to the newly created feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RET_1</th>\n",
       "      <th>RET_2</th>\n",
       "      <th>RET_3</th>\n",
       "      <th>RET_7</th>\n",
       "      <th>RET_14</th>\n",
       "      <th>RET_17</th>\n",
       "      <th>VOLUME_1</th>\n",
       "      <th>RET_1_STOCK_mean</th>\n",
       "      <th>RET_2_STOCK_mean</th>\n",
       "      <th>RET_3_STOCK_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>VOLUME_13_STOCK_mean</th>\n",
       "      <th>VOLUME_14_STOCK_mean</th>\n",
       "      <th>VOLUME_15_STOCK_mean</th>\n",
       "      <th>VOLUME_16_STOCK_mean</th>\n",
       "      <th>VOLUME_17_STOCK_mean</th>\n",
       "      <th>VOLUME_18_STOCK_mean</th>\n",
       "      <th>VOLUME_19_STOCK_mean</th>\n",
       "      <th>VOLUME_20_STOCK_mean</th>\n",
       "      <th>VOLUME_1_STOCK_SECTOR_INDUSTRY_DATE_mean</th>\n",
       "      <th>VOLUME_13_STOCK_SECTOR_INDUSTRY_DATE_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.015748</td>\n",
       "      <td>-0.015504</td>\n",
       "      <td>0.010972</td>\n",
       "      <td>-0.017215</td>\n",
       "      <td>-0.049370</td>\n",
       "      <td>0.003254</td>\n",
       "      <td>0.147931</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>0.003829</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.254376</td>\n",
       "      <td>-0.368684</td>\n",
       "      <td>-0.320473</td>\n",
       "      <td>-0.413497</td>\n",
       "      <td>-0.346483</td>\n",
       "      <td>-0.261443</td>\n",
       "      <td>-0.171050</td>\n",
       "      <td>-0.182507</td>\n",
       "      <td>0.147931</td>\n",
       "      <td>-0.244636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003984</td>\n",
       "      <td>-0.090580</td>\n",
       "      <td>0.018826</td>\n",
       "      <td>-0.026756</td>\n",
       "      <td>-0.052044</td>\n",
       "      <td>0.003774</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005551</td>\n",
       "      <td>-0.004266</td>\n",
       "      <td>-0.000460</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000440</td>\n",
       "      <td>-0.058896</td>\n",
       "      <td>-0.009042</td>\n",
       "      <td>-0.023047</td>\n",
       "      <td>-0.002686</td>\n",
       "      <td>-0.017612</td>\n",
       "      <td>-0.096282</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>0.002516</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.076037</td>\n",
       "      <td>-0.109735</td>\n",
       "      <td>-0.002067</td>\n",
       "      <td>-0.044647</td>\n",
       "      <td>-0.064004</td>\n",
       "      <td>0.023585</td>\n",
       "      <td>-0.045170</td>\n",
       "      <td>0.004909</td>\n",
       "      <td>-0.096282</td>\n",
       "      <td>-0.081783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.031298</td>\n",
       "      <td>0.007756</td>\n",
       "      <td>-0.004632</td>\n",
       "      <td>-0.043962</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.033824</td>\n",
       "      <td>-0.429540</td>\n",
       "      <td>0.001422</td>\n",
       "      <td>-0.002775</td>\n",
       "      <td>0.002287</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.057720</td>\n",
       "      <td>-0.285352</td>\n",
       "      <td>-0.306822</td>\n",
       "      <td>-0.109386</td>\n",
       "      <td>-0.316047</td>\n",
       "      <td>-0.157600</td>\n",
       "      <td>-0.199309</td>\n",
       "      <td>0.088587</td>\n",
       "      <td>-0.429540</td>\n",
       "      <td>-0.839232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.027273</td>\n",
       "      <td>-0.039302</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.026549</td>\n",
       "      <td>0.095891</td>\n",
       "      <td>-0.012659</td>\n",
       "      <td>-0.847155</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.003006</td>\n",
       "      <td>-0.000166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011901</td>\n",
       "      <td>0.444344</td>\n",
       "      <td>1.491632</td>\n",
       "      <td>-0.095353</td>\n",
       "      <td>-0.111839</td>\n",
       "      <td>-0.100428</td>\n",
       "      <td>0.981283</td>\n",
       "      <td>-0.155964</td>\n",
       "      <td>-0.847155</td>\n",
       "      <td>0.271702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       RET_1     RET_2     RET_3     RET_7    RET_14    RET_17  VOLUME_1  \\\n",
       "ID                                                                         \n",
       "0  -0.015748 -0.015504  0.010972 -0.017215 -0.049370  0.003254  0.147931   \n",
       "1   0.003984 -0.090580  0.018826 -0.026756 -0.052044  0.003774       NaN   \n",
       "2   0.000440 -0.058896 -0.009042 -0.023047 -0.002686 -0.017612 -0.096282   \n",
       "3   0.031298  0.007756 -0.004632 -0.043962  0.000479  0.033824 -0.429540   \n",
       "4   0.027273 -0.039302  0.000000 -0.026549  0.095891 -0.012659 -0.847155   \n",
       "\n",
       "    RET_1_STOCK_mean  RET_2_STOCK_mean  RET_3_STOCK_mean  ...  \\\n",
       "ID                                                        ...   \n",
       "0           0.001285          0.003829          0.000226  ...   \n",
       "1           0.005551         -0.004266         -0.000460  ...   \n",
       "2           0.001534          0.000244          0.002516  ...   \n",
       "3           0.001422         -0.002775          0.002287  ...   \n",
       "4           0.001017          0.003006         -0.000166  ...   \n",
       "\n",
       "    VOLUME_13_STOCK_mean  VOLUME_14_STOCK_mean  VOLUME_15_STOCK_mean  \\\n",
       "ID                                                                     \n",
       "0              -0.254376             -0.368684             -0.320473   \n",
       "1                    NaN                   NaN                   NaN   \n",
       "2              -0.076037             -0.109735             -0.002067   \n",
       "3              -0.057720             -0.285352             -0.306822   \n",
       "4               0.011901              0.444344              1.491632   \n",
       "\n",
       "    VOLUME_16_STOCK_mean  VOLUME_17_STOCK_mean  VOLUME_18_STOCK_mean  \\\n",
       "ID                                                                     \n",
       "0              -0.413497             -0.346483             -0.261443   \n",
       "1                    NaN                   NaN                   NaN   \n",
       "2              -0.044647             -0.064004              0.023585   \n",
       "3              -0.109386             -0.316047             -0.157600   \n",
       "4              -0.095353             -0.111839             -0.100428   \n",
       "\n",
       "    VOLUME_19_STOCK_mean  VOLUME_20_STOCK_mean  \\\n",
       "ID                                               \n",
       "0              -0.171050             -0.182507   \n",
       "1                    NaN                   NaN   \n",
       "2              -0.045170              0.004909   \n",
       "3              -0.199309              0.088587   \n",
       "4               0.981283             -0.155964   \n",
       "\n",
       "    VOLUME_1_STOCK_SECTOR_INDUSTRY_DATE_mean  \\\n",
       "ID                                             \n",
       "0                                   0.147931   \n",
       "1                                        NaN   \n",
       "2                                  -0.096282   \n",
       "3                                  -0.429540   \n",
       "4                                  -0.847155   \n",
       "\n",
       "    VOLUME_13_STOCK_SECTOR_INDUSTRY_DATE_mean  \n",
       "ID                                             \n",
       "0                                   -0.244636  \n",
       "1                                         NaN  \n",
       "2                                   -0.081783  \n",
       "3                                   -0.839232  \n",
       "4                                    0.271702  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'RET'\n",
    "\n",
    "n_shifts = [1,2,3,7,14,17]\n",
    "features = ['RET_%d' % i for i in n_shifts]\n",
    "# features += ['VOLUME_1','DATE']\n",
    "features += ['VOLUME_1']\n",
    "\n",
    "features += new_features  # The conditional features\n",
    "train[features].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and local score\n",
    "\n",
    "A Random Forest (RF) model is chosen for the Benchmark. We consider a large number of tree with a quiet small depth. The missing values are simply filled with 0. A KFold is done on the dates (using `DATE`) for a local scoring of the model. \n",
    "\n",
    "**Ideas of improvements**: Tune the RF hyperparameters, deal with the missing values, change the features, consider another model, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yangjujie/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Accuracy: 51.60%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yangjujie/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 2 - Accuracy: 51.37%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yangjujie/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 3 - Accuracy: 51.01%\n",
      "Fold 4 - Accuracy: 50.92%\n",
      "Accuracy: 51.22% [50.95 ; 51.50] (+- 0.27)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yangjujie/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "X_train = train[features]\n",
    "y_train = train[target]\n",
    "\n",
    "# A quiet large number of trees with low depth to prevent overfits\n",
    "rf_params = {\n",
    "    'n_estimators': 500,\n",
    "    'max_depth': 2**3,\n",
    "    'random_state': 0,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "train_dates = train['DATE'].unique()\n",
    "test_dates = test['DATE'].unique()\n",
    "\n",
    "n_splits = 4\n",
    "scores = []\n",
    "\n",
    "models = []\n",
    "\n",
    "splits = KFold(n_splits=n_splits, random_state=0,\n",
    "               shuffle=True).split(train_dates)\n",
    "\n",
    "for i, (local_train_dates_ids, local_test_dates_ids) in enumerate(splits):\n",
    "    local_train_dates = train_dates[local_train_dates_ids]\n",
    "    local_test_dates = train_dates[local_test_dates_ids]\n",
    "\n",
    "    local_train_ids = train['DATE'].isin(local_train_dates)\n",
    "    local_test_ids = train['DATE'].isin(local_test_dates)\n",
    "\n",
    "    X_local_train = X_train.loc[local_train_ids]\n",
    "    y_local_train = y_train.loc[local_train_ids]\n",
    "    X_local_test = X_train.loc[local_test_ids]\n",
    "    y_local_test = y_train.loc[local_test_ids]\n",
    "\n",
    "    X_local_train = X_local_train.fillna(0)\n",
    "    X_local_test = X_local_test.fillna(0)\n",
    "\n",
    "#     model = RandomForestClassifier(**rf_params)\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_local_train, y_local_train)\n",
    "\n",
    "    y_local_pred = model.predict_proba(X_local_test)[:, 1]\n",
    "    \n",
    "    sub = train.loc[local_test_ids].copy()\n",
    "    sub['pred'] = y_local_pred\n",
    "    y_local_pred = sub.groupby('DATE')['pred'].transform(lambda x: x > x.median()).values\n",
    "\n",
    "    models.append(model)\n",
    "    score = accuracy_score(y_local_test, y_local_pred)\n",
    "    scores.append(score)\n",
    "    print(f\"Fold {i+1} - Accuracy: {score* 100:.2f}%\")\n",
    "\n",
    "mean = np.mean(scores)*100\n",
    "std = np.std(scores)*100\n",
    "u = (mean + std)\n",
    "l = (mean - std)\n",
    "print(f'Accuracy: {mean:.2f}% [{l:.2f} ; {u:.2f}] (+- {std:.2f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the submission\n",
    "\n",
    "The same parameters of the RF model are considered. With that we build a new RF model on the entire `train` dataset. The predictions are saved in a `.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d5ede2824fd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# model.fit(X_train.fillna(0), y_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# y_pred = model.predict_proba(X_test.fillna(0))[:, 1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0msub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "X_test = test[features]\n",
    "\n",
    "# rf_params['random_state'] = 0\n",
    "# model = RandomForestClassifier(**rf_params)\n",
    "# model = \n",
    "# model.fit(X_train.fillna(0), y_train)\n",
    "# y_pred = model.predict_proba(X_test.fillna(0))[:, 1]\n",
    "y_pred = model.predict(X_test.fillna(0))[:, 1]\n",
    "\n",
    "sub = test.copy()\n",
    "sub['pred'] = y_pred\n",
    "y_pred = sub.groupby('DATE')['pred'].transform(\n",
    "    lambda x: x > x.median()).values\n",
    "\n",
    "submission = pd.Series(y_pred)\n",
    "submission.index = test.index\n",
    "submission.name = target\n",
    "\n",
    "submission.to_csv('./logistic.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The local accuracy is around 51. If we did not overfit, we shall expect something within the range above.\n",
    "\n",
    "After submitting the benchmark file at https://challengedata.ens.fr, we obtain a public score of 51.31 %."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
