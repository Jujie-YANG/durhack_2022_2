{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark QRT\n",
    "\n",
    "This notebook illustrates a simple benchmark example that should help novice participants to start the competition.\n",
    "\n",
    "## Used libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data\n",
    "\n",
    "The train and test inputs are composed of 46 features.\n",
    "\n",
    "The target of this challenge is `RET` and corresponds to the fact that the **return is in the top 50% of highest stock returns**.\n",
    "\n",
    "Since the median is very close to 0, this information should not change much with the idea to predict the sign of the return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DATE</th>\n",
       "      <th>STOCK</th>\n",
       "      <th>INDUSTRY</th>\n",
       "      <th>INDUSTRY_GROUP</th>\n",
       "      <th>SECTOR</th>\n",
       "      <th>SUB_INDUSTRY</th>\n",
       "      <th>RET_1</th>\n",
       "      <th>VOLUME_1</th>\n",
       "      <th>RET_2</th>\n",
       "      <th>VOLUME_2</th>\n",
       "      <th>...</th>\n",
       "      <th>VOLUME_16</th>\n",
       "      <th>RET_17</th>\n",
       "      <th>VOLUME_17</th>\n",
       "      <th>RET_18</th>\n",
       "      <th>VOLUME_18</th>\n",
       "      <th>RET_19</th>\n",
       "      <th>VOLUME_19</th>\n",
       "      <th>RET_20</th>\n",
       "      <th>VOLUME_20</th>\n",
       "      <th>RET</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>-0.015748</td>\n",
       "      <td>0.147931</td>\n",
       "      <td>-0.015504</td>\n",
       "      <td>0.179183</td>\n",
       "      <td>...</td>\n",
       "      <td>0.630899</td>\n",
       "      <td>0.003254</td>\n",
       "      <td>-0.379412</td>\n",
       "      <td>0.008752</td>\n",
       "      <td>-0.110597</td>\n",
       "      <td>-0.012959</td>\n",
       "      <td>0.174521</td>\n",
       "      <td>-0.002155</td>\n",
       "      <td>-0.000937</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>104</td>\n",
       "      <td>0.003984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.090580</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003774</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.018518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.028777</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.034722</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>142</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>-0.096282</td>\n",
       "      <td>-0.058896</td>\n",
       "      <td>0.084771</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010336</td>\n",
       "      <td>-0.017612</td>\n",
       "      <td>-0.354333</td>\n",
       "      <td>-0.006562</td>\n",
       "      <td>-0.519391</td>\n",
       "      <td>-0.012101</td>\n",
       "      <td>-0.356157</td>\n",
       "      <td>-0.006867</td>\n",
       "      <td>-0.308868</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.031298</td>\n",
       "      <td>-0.429540</td>\n",
       "      <td>0.007756</td>\n",
       "      <td>-0.089919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012105</td>\n",
       "      <td>0.033824</td>\n",
       "      <td>-0.290178</td>\n",
       "      <td>-0.001468</td>\n",
       "      <td>-0.663834</td>\n",
       "      <td>-0.013520</td>\n",
       "      <td>-0.562126</td>\n",
       "      <td>-0.036745</td>\n",
       "      <td>-0.631458</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>36</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>92</td>\n",
       "      <td>0.027273</td>\n",
       "      <td>-0.847155</td>\n",
       "      <td>-0.039302</td>\n",
       "      <td>-0.943033</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.277083</td>\n",
       "      <td>-0.012659</td>\n",
       "      <td>0.139086</td>\n",
       "      <td>0.004237</td>\n",
       "      <td>-0.017547</td>\n",
       "      <td>0.004256</td>\n",
       "      <td>0.579510</td>\n",
       "      <td>-0.040817</td>\n",
       "      <td>0.802806</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    DATE  STOCK  INDUSTRY  INDUSTRY_GROUP  SECTOR  SUB_INDUSTRY     RET_1  \\\n",
       "ID                                                                          \n",
       "0      0      2        18               5       3            44 -0.015748   \n",
       "1      0      3        43              15       6           104  0.003984   \n",
       "2      0      4        57              20       8           142  0.000440   \n",
       "3      0      8         1               1       1             2  0.031298   \n",
       "4      0     14        36              12       5            92  0.027273   \n",
       "\n",
       "    VOLUME_1     RET_2  VOLUME_2  ...  VOLUME_16    RET_17  VOLUME_17  \\\n",
       "ID                                ...                                   \n",
       "0   0.147931 -0.015504  0.179183  ...   0.630899  0.003254  -0.379412   \n",
       "1        NaN -0.090580       NaN  ...        NaN  0.003774        NaN   \n",
       "2  -0.096282 -0.058896  0.084771  ...  -0.010336 -0.017612  -0.354333   \n",
       "3  -0.429540  0.007756 -0.089919  ...   0.012105  0.033824  -0.290178   \n",
       "4  -0.847155 -0.039302 -0.943033  ...  -0.277083 -0.012659   0.139086   \n",
       "\n",
       "      RET_18  VOLUME_18    RET_19  VOLUME_19    RET_20  VOLUME_20    RET  \n",
       "ID                                                                        \n",
       "0   0.008752  -0.110597 -0.012959   0.174521 -0.002155  -0.000937   True  \n",
       "1  -0.018518        NaN -0.028777        NaN -0.034722        NaN   True  \n",
       "2  -0.006562  -0.519391 -0.012101  -0.356157 -0.006867  -0.308868  False  \n",
       "3  -0.001468  -0.663834 -0.013520  -0.562126 -0.036745  -0.631458  False  \n",
       "4   0.004237  -0.017547  0.004256   0.579510 -0.040817   0.802806  False  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train = pd.read_csv('../data/x_train.csv', index_col='ID')\n",
    "y_train = pd.read_csv('../data/y_train.csv', index_col='ID')\n",
    "train = pd.concat([x_train, y_train], axis=1)\n",
    "test = pd.read_csv('../data/x_test.csv', index_col='ID')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "\n",
    "The main drawback in this challenge would be to deal with the noise. To do that, we could create some feature that aggregate features with some statistics. \n",
    "\n",
    "The following cell computes statistics on a given target conditionally to some features. For example, we want to generate a feature that describe the mean of `RET_1` conditionally to the `SECTOR` and the `DATE`.\n",
    "\n",
    "**Ideas of improvement**: change shifts, the conditional features, the statistics, and the target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature engineering\n",
    "new_features = []\n",
    "\n",
    "# Conditional aggregated features\n",
    "shifts = [i for i in range(1,21)]  # Choose some different shifts\n",
    "statistics = ['mean']  # the type of stat\n",
    "\n",
    "# GROUP BY 4 features only for \"RET\", shifts = [1,...,21]\n",
    "gb_features = ['STOCK','SECTOR','INDUSTRY', 'DATE']\n",
    "target_feature = ['RET']\n",
    "tmp_name = '_'.join(gb_features)\n",
    "for j in target_feature:\n",
    "    for shift in shifts:\n",
    "        for stat in statistics:\n",
    "            name = f'{j}_{shift}_{tmp_name}_{stat}'\n",
    "            feat = f'{j}_{shift}'\n",
    "            new_features.append(name)\n",
    "            for data in [train, test]:\n",
    "                data[name] = data.groupby(gb_features)[feat].transform(stat)\n",
    "           \n",
    "        \n",
    "# # GROUP BY \"DATE\" for features['RET','VOLUME'], shifts=[1,...,21]\n",
    "# gb_features = ['DATE']\n",
    "# target_features = ['RET','VOLUME']\n",
    "# tmp_name = '_'.join(gb_features)\n",
    "# for j in target_features:\n",
    "# #     target_feature = j\n",
    "#     for shift in shifts:\n",
    "#         for stat in statistics:\n",
    "#             name = f'{j}_{shift}_{tmp_name}_{stat}'\n",
    "#             feat = f'{j}_{shift}'\n",
    "#             new_features.append(name)\n",
    "#             for data in [train, test]:\n",
    "#                 data[name] = data.groupby(gb_features)[feat].transform(stat)\n",
    "\n",
    "        \n",
    "# # GROUP BY \"STOCK\" for features['RET','VOLUME'], shifts=[1,...,21]\n",
    "# gb_features = ['STOCK']\n",
    "# target_features = ['RET','VOLUME']\n",
    "# tmp_name = '_'.join(gb_features)\n",
    "# for j in target_features:\n",
    "# #     target_feature = j\n",
    "#     for shift in shifts:\n",
    "#         for stat in statistics:\n",
    "#             name = f'{j}_{shift}_{tmp_name}_{stat}'\n",
    "#             feat = f'{j}_{shift}'\n",
    "#             new_features.append(name)\n",
    "#             for data in [train, test]:\n",
    "#                 data[name] = data.groupby(gb_features)[feat].transform(stat)\n",
    "\n",
    "                \n",
    "gb_features = ['STOCK','SECTOR','INDUSTRY', 'DATE']\n",
    "target_feature = \"VOLUME\"\n",
    "shifts = [1,13]\n",
    "tmp_name = '_'.join(gb_features)\n",
    "for shift in shifts:\n",
    "    for stat in statistics:\n",
    "        name = f'{target_feature}_{shift}_{tmp_name}_{stat}'\n",
    "        feat = f'{target_feature}_{shift}'\n",
    "        new_features.append(name)\n",
    "        for data in [train, test]:\n",
    "            data[name] = data.groupby(gb_features)[feat].transform(stat)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection\n",
    "\n",
    "To reduce the number of feature (and the noise) we only consider the 5 last days of `RET` and `VOLUME` in addition to the newly created feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RET_1</th>\n",
       "      <th>RET_2</th>\n",
       "      <th>RET_3</th>\n",
       "      <th>RET_7</th>\n",
       "      <th>RET_14</th>\n",
       "      <th>RET_17</th>\n",
       "      <th>VOLUME_1</th>\n",
       "      <th>RET_1_STOCK_SECTOR_INDUSTRY_DATE_mean</th>\n",
       "      <th>RET_2_STOCK_SECTOR_INDUSTRY_DATE_mean</th>\n",
       "      <th>RET_3_STOCK_SECTOR_INDUSTRY_DATE_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>RET_13_STOCK_SECTOR_INDUSTRY_DATE_mean</th>\n",
       "      <th>RET_14_STOCK_SECTOR_INDUSTRY_DATE_mean</th>\n",
       "      <th>RET_15_STOCK_SECTOR_INDUSTRY_DATE_mean</th>\n",
       "      <th>RET_16_STOCK_SECTOR_INDUSTRY_DATE_mean</th>\n",
       "      <th>RET_17_STOCK_SECTOR_INDUSTRY_DATE_mean</th>\n",
       "      <th>RET_18_STOCK_SECTOR_INDUSTRY_DATE_mean</th>\n",
       "      <th>RET_19_STOCK_SECTOR_INDUSTRY_DATE_mean</th>\n",
       "      <th>RET_20_STOCK_SECTOR_INDUSTRY_DATE_mean</th>\n",
       "      <th>VOLUME_1_STOCK_SECTOR_INDUSTRY_DATE_mean</th>\n",
       "      <th>VOLUME_13_STOCK_SECTOR_INDUSTRY_DATE_mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.015748</td>\n",
       "      <td>-0.015504</td>\n",
       "      <td>0.010972</td>\n",
       "      <td>-0.017215</td>\n",
       "      <td>-0.049370</td>\n",
       "      <td>0.003254</td>\n",
       "      <td>0.147931</td>\n",
       "      <td>-0.015748</td>\n",
       "      <td>-0.015504</td>\n",
       "      <td>0.010972</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027624</td>\n",
       "      <td>-0.049370</td>\n",
       "      <td>-0.028571</td>\n",
       "      <td>0.059459</td>\n",
       "      <td>0.003254</td>\n",
       "      <td>0.008752</td>\n",
       "      <td>-0.012959</td>\n",
       "      <td>-0.002155</td>\n",
       "      <td>0.147931</td>\n",
       "      <td>-0.244636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003984</td>\n",
       "      <td>-0.090580</td>\n",
       "      <td>0.018826</td>\n",
       "      <td>-0.026756</td>\n",
       "      <td>-0.052044</td>\n",
       "      <td>0.003774</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.003984</td>\n",
       "      <td>-0.090580</td>\n",
       "      <td>0.018826</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019608</td>\n",
       "      <td>-0.052044</td>\n",
       "      <td>-0.004073</td>\n",
       "      <td>0.015413</td>\n",
       "      <td>0.003774</td>\n",
       "      <td>-0.018518</td>\n",
       "      <td>-0.028777</td>\n",
       "      <td>-0.034722</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000440</td>\n",
       "      <td>-0.058896</td>\n",
       "      <td>-0.009042</td>\n",
       "      <td>-0.023047</td>\n",
       "      <td>-0.002686</td>\n",
       "      <td>-0.017612</td>\n",
       "      <td>-0.096282</td>\n",
       "      <td>0.000440</td>\n",
       "      <td>-0.058896</td>\n",
       "      <td>-0.009042</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009426</td>\n",
       "      <td>-0.002686</td>\n",
       "      <td>-0.007552</td>\n",
       "      <td>0.008964</td>\n",
       "      <td>-0.017612</td>\n",
       "      <td>-0.006562</td>\n",
       "      <td>-0.012101</td>\n",
       "      <td>-0.006867</td>\n",
       "      <td>-0.096282</td>\n",
       "      <td>-0.081783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.031298</td>\n",
       "      <td>0.007756</td>\n",
       "      <td>-0.004632</td>\n",
       "      <td>-0.043962</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.033824</td>\n",
       "      <td>-0.429540</td>\n",
       "      <td>0.031298</td>\n",
       "      <td>0.007756</td>\n",
       "      <td>-0.004632</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010067</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.021057</td>\n",
       "      <td>-0.031769</td>\n",
       "      <td>0.033824</td>\n",
       "      <td>-0.001468</td>\n",
       "      <td>-0.013520</td>\n",
       "      <td>-0.036745</td>\n",
       "      <td>-0.429540</td>\n",
       "      <td>-0.839232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.027273</td>\n",
       "      <td>-0.039302</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.026549</td>\n",
       "      <td>0.095891</td>\n",
       "      <td>-0.012659</td>\n",
       "      <td>-0.847155</td>\n",
       "      <td>0.027273</td>\n",
       "      <td>-0.039302</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041667</td>\n",
       "      <td>0.095891</td>\n",
       "      <td>-0.026667</td>\n",
       "      <td>-0.038461</td>\n",
       "      <td>-0.012659</td>\n",
       "      <td>0.004237</td>\n",
       "      <td>0.004256</td>\n",
       "      <td>-0.040817</td>\n",
       "      <td>-0.847155</td>\n",
       "      <td>0.271702</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       RET_1     RET_2     RET_3     RET_7    RET_14    RET_17  VOLUME_1  \\\n",
       "ID                                                                         \n",
       "0  -0.015748 -0.015504  0.010972 -0.017215 -0.049370  0.003254  0.147931   \n",
       "1   0.003984 -0.090580  0.018826 -0.026756 -0.052044  0.003774       NaN   \n",
       "2   0.000440 -0.058896 -0.009042 -0.023047 -0.002686 -0.017612 -0.096282   \n",
       "3   0.031298  0.007756 -0.004632 -0.043962  0.000479  0.033824 -0.429540   \n",
       "4   0.027273 -0.039302  0.000000 -0.026549  0.095891 -0.012659 -0.847155   \n",
       "\n",
       "    RET_1_STOCK_SECTOR_INDUSTRY_DATE_mean  \\\n",
       "ID                                          \n",
       "0                               -0.015748   \n",
       "1                                0.003984   \n",
       "2                                0.000440   \n",
       "3                                0.031298   \n",
       "4                                0.027273   \n",
       "\n",
       "    RET_2_STOCK_SECTOR_INDUSTRY_DATE_mean  \\\n",
       "ID                                          \n",
       "0                               -0.015504   \n",
       "1                               -0.090580   \n",
       "2                               -0.058896   \n",
       "3                                0.007756   \n",
       "4                               -0.039302   \n",
       "\n",
       "    RET_3_STOCK_SECTOR_INDUSTRY_DATE_mean  ...  \\\n",
       "ID                                         ...   \n",
       "0                                0.010972  ...   \n",
       "1                                0.018826  ...   \n",
       "2                               -0.009042  ...   \n",
       "3                               -0.004632  ...   \n",
       "4                                0.000000  ...   \n",
       "\n",
       "    RET_13_STOCK_SECTOR_INDUSTRY_DATE_mean  \\\n",
       "ID                                           \n",
       "0                                 0.027624   \n",
       "1                                -0.019608   \n",
       "2                                -0.009426   \n",
       "3                                -0.010067   \n",
       "4                                -0.041667   \n",
       "\n",
       "    RET_14_STOCK_SECTOR_INDUSTRY_DATE_mean  \\\n",
       "ID                                           \n",
       "0                                -0.049370   \n",
       "1                                -0.052044   \n",
       "2                                -0.002686   \n",
       "3                                 0.000479   \n",
       "4                                 0.095891   \n",
       "\n",
       "    RET_15_STOCK_SECTOR_INDUSTRY_DATE_mean  \\\n",
       "ID                                           \n",
       "0                                -0.028571   \n",
       "1                                -0.004073   \n",
       "2                                -0.007552   \n",
       "3                                 0.021057   \n",
       "4                                -0.026667   \n",
       "\n",
       "    RET_16_STOCK_SECTOR_INDUSTRY_DATE_mean  \\\n",
       "ID                                           \n",
       "0                                 0.059459   \n",
       "1                                 0.015413   \n",
       "2                                 0.008964   \n",
       "3                                -0.031769   \n",
       "4                                -0.038461   \n",
       "\n",
       "    RET_17_STOCK_SECTOR_INDUSTRY_DATE_mean  \\\n",
       "ID                                           \n",
       "0                                 0.003254   \n",
       "1                                 0.003774   \n",
       "2                                -0.017612   \n",
       "3                                 0.033824   \n",
       "4                                -0.012659   \n",
       "\n",
       "    RET_18_STOCK_SECTOR_INDUSTRY_DATE_mean  \\\n",
       "ID                                           \n",
       "0                                 0.008752   \n",
       "1                                -0.018518   \n",
       "2                                -0.006562   \n",
       "3                                -0.001468   \n",
       "4                                 0.004237   \n",
       "\n",
       "    RET_19_STOCK_SECTOR_INDUSTRY_DATE_mean  \\\n",
       "ID                                           \n",
       "0                                -0.012959   \n",
       "1                                -0.028777   \n",
       "2                                -0.012101   \n",
       "3                                -0.013520   \n",
       "4                                 0.004256   \n",
       "\n",
       "    RET_20_STOCK_SECTOR_INDUSTRY_DATE_mean  \\\n",
       "ID                                           \n",
       "0                                -0.002155   \n",
       "1                                -0.034722   \n",
       "2                                -0.006867   \n",
       "3                                -0.036745   \n",
       "4                                -0.040817   \n",
       "\n",
       "    VOLUME_1_STOCK_SECTOR_INDUSTRY_DATE_mean  \\\n",
       "ID                                             \n",
       "0                                   0.147931   \n",
       "1                                        NaN   \n",
       "2                                  -0.096282   \n",
       "3                                  -0.429540   \n",
       "4                                  -0.847155   \n",
       "\n",
       "    VOLUME_13_STOCK_SECTOR_INDUSTRY_DATE_mean  \n",
       "ID                                             \n",
       "0                                   -0.244636  \n",
       "1                                         NaN  \n",
       "2                                   -0.081783  \n",
       "3                                   -0.839232  \n",
       "4                                    0.271702  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = 'RET'\n",
    "\n",
    "n_shifts = [1,2,3,7,14,17]\n",
    "features = ['RET_%d' % i for i in n_shifts]\n",
    "# features += ['VOLUME_1','DATE']\n",
    "features += ['VOLUME_1']\n",
    "\n",
    "features += new_features  # The conditional features\n",
    "train[features].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and local score\n",
    "\n",
    "A Random Forest (RF) model is chosen for the Benchmark. We consider a large number of tree with a quiet small depth. The missing values are simply filled with 0. A KFold is done on the dates (using `DATE`) for a local scoring of the model. \n",
    "\n",
    "**Ideas of improvements**: Tune the RF hyperparameters, deal with the missing values, change the features, consider another model, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 - Accuracy: 50.53%\n",
      "Fold 2 - Accuracy: 51.30%\n",
      "Fold 3 - Accuracy: 50.84%\n",
      "Fold 4 - Accuracy: 50.23%\n",
      "Accuracy: 50.73% [50.33 ; 51.12] (+- 0.40)\n"
     ]
    }
   ],
   "source": [
    "X_train = train[features]\n",
    "y_train = train[target]\n",
    "\n",
    "# A quiet large number of trees with low depth to prevent overfits\n",
    "rf_params = {\n",
    "    'n_estimators': 500,\n",
    "    'max_depth': 2**3,\n",
    "    'random_state': 0,\n",
    "    'n_jobs': -1\n",
    "}\n",
    "\n",
    "train_dates = train['DATE'].unique()\n",
    "test_dates = test['DATE'].unique()\n",
    "\n",
    "n_splits = 4\n",
    "scores = []\n",
    "\n",
    "models = []\n",
    "\n",
    "splits = KFold(n_splits=n_splits, random_state=0,\n",
    "               shuffle=True).split(train_dates)\n",
    "\n",
    "for i, (local_train_dates_ids, local_test_dates_ids) in enumerate(splits):\n",
    "    local_train_dates = train_dates[local_train_dates_ids]\n",
    "    local_test_dates = train_dates[local_test_dates_ids]\n",
    "\n",
    "    local_train_ids = train['DATE'].isin(local_train_dates)\n",
    "    local_test_ids = train['DATE'].isin(local_test_dates)\n",
    "\n",
    "    X_local_train = X_train.loc[local_train_ids]\n",
    "    y_local_train = y_train.loc[local_train_ids]\n",
    "    X_local_test = X_train.loc[local_test_ids]\n",
    "    y_local_test = y_train.loc[local_test_ids]\n",
    "\n",
    "    X_local_train = X_local_train.fillna(0)\n",
    "    X_local_test = X_local_test.fillna(0)\n",
    "\n",
    "#     model = RandomForestClassifier(**rf_params)\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_local_train, y_local_train)\n",
    "\n",
    "    y_local_pred = model.predict_proba(X_local_test)[:, 1]\n",
    "    \n",
    "    sub = train.loc[local_test_ids].copy()\n",
    "    sub['pred'] = y_local_pred\n",
    "    y_local_pred = sub.groupby('DATE')['pred'].transform(lambda x: x > x.median()).values\n",
    "\n",
    "    models.append(model)\n",
    "    score = accuracy_score(y_local_test, y_local_pred)\n",
    "    scores.append(score)\n",
    "    print(f\"Fold {i+1} - Accuracy: {score* 100:.2f}%\")\n",
    "\n",
    "mean = np.mean(scores)*100\n",
    "std = np.std(scores)*100\n",
    "u = (mean + std)\n",
    "l = (mean - std)\n",
    "print(f'Accuracy: {mean:.2f}% [{l:.2f} ; {u:.2f}] (+- {std:.2f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the submission\n",
    "\n",
    "The same parameters of the RF model are considered. With that we build a new RF model on the entire `train` dataset. The predictions are saved in a `.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d5ede2824fd1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# model.fit(X_train.fillna(0), y_train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# y_pred = model.predict_proba(X_test.fillna(0))[:, 1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0msub\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "X_test = test[features]\n",
    "\n",
    "# rf_params['random_state'] = 0\n",
    "# model = RandomForestClassifier(**rf_params)\n",
    "# model = \n",
    "# model.fit(X_train.fillna(0), y_train)\n",
    "# y_pred = model.predict_proba(X_test.fillna(0))[:, 1]\n",
    "y_pred = model.predict(X_test.fillna(0))[:, 1]\n",
    "\n",
    "sub = test.copy()\n",
    "sub['pred'] = y_pred\n",
    "y_pred = sub.groupby('DATE')['pred'].transform(\n",
    "    lambda x: x > x.median()).values\n",
    "\n",
    "submission = pd.Series(y_pred)\n",
    "submission.index = test.index\n",
    "submission.name = target\n",
    "\n",
    "submission.to_csv('./logistic.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The local accuracy is around 51. If we did not overfit, we shall expect something within the range above.\n",
    "\n",
    "After submitting the benchmark file at https://challengedata.ens.fr, we obtain a public score of 51.31 %."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
